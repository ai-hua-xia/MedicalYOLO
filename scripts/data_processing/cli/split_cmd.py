"""
æ•°æ®é›†åˆ†å‰²å‘½ä»¤è¡Œæ¥å£
"""
import argparse
import shutil
import sys
import logging
from pathlib import Path
from typing import List
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from scripts.data_processing.core import DatasetSplitter
from scripts.data_processing.utils import read_classes_file

def clean_previous_split(output_dir: Path):
    """æ¸…ç†æ—§çš„åˆ’åˆ†ç›®å½•å’Œ configs/data.yaml æ–‡ä»¶"""
    for sub in ['train', 'val', 'test']:
        sub_dir = output_dir / sub
        if sub_dir.exists():
            shutil.rmtree(sub_dir)
            print(f"ğŸ§¹ å·²åˆ é™¤ç›®å½•: {sub_dir}")
    yaml_file = Path("configs/data.yaml")
    if yaml_file.exists():
        yaml_file.unlink()
        print(f"ğŸ§¹ å·²åˆ é™¤é…ç½®æ–‡ä»¶: {yaml_file}")

def write_data_yaml(output_dir: Path, class_names: list):
    yaml_file = Path("configs/data.yaml")  # å›ºå®šè¾“å‡ºåˆ° configs/data.yaml
    yaml_content = f"""path: {output_dir.resolve()}
train: {output_dir.resolve() / 'train/images'}
val: {output_dir.resolve() / 'val/images'}
test: {output_dir.resolve() / 'test/images'}
nc: {len(class_names)}
names: {class_names}
"""
    yaml_file.parent.mkdir(parents=True, exist_ok=True)
    with open(yaml_file, 'w', encoding='utf-8') as f:
        f.write(yaml_content)
    print(f"ğŸ“„ å·²ç”Ÿæˆé…ç½®æ–‡ä»¶: {yaml_file}")

def setup_logging(verbose: bool = False):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    level = logging.DEBUG if verbose else logging.INFO
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f'logging/dataset_split/dataset_split_{timestamp}.log'
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_filename)
        ]
    )

def validate_ratios(train: float, val: float, test: float) -> bool:
    """éªŒè¯åˆ†å‰²æ¯”ä¾‹"""
    total = train + val + test
    if abs(total - 1.0) > 1e-6:
        print(f"âŒ åˆ†å‰²æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º1.0ï¼Œå½“å‰ä¸º: {total}")
        return False
    
    if train <= 0 or val < 0 or test < 0:
        print("âŒ åˆ†å‰²æ¯”ä¾‹å¿…é¡»ä¸ºæ­£æ•°")
        return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="MedicalYOLO æ•°æ®é›†åˆ†å‰²å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # æŒ‰æ¯”ä¾‹åˆ†å‰²æ•°æ®é›†
  python split_cmd.py -i /path/to/dataset -o /path/to/output --train 0.7 --val 0.2 --test 0.1
  
  # æŒ‰ç±»åˆ«å¹³è¡¡åˆ†å‰²
  python split_cmd.py -i /path/to/dataset -o /path/to/output --by-class --train 0.8 --val 0.2
  
  # ç”ŸæˆYOLOé…ç½®æ–‡ä»¶
  python split_cmd.py -i /path/to/dataset -o /path/to/output --create-yaml --classes /path/to/classes.txt
        """
    )
    
    parser.add_argument(
        '-i', '--input',
    default='data/raw/images',
    help='è¾“å…¥å›¾ç‰‡è·¯å¾„ (é»˜è®¤: data/raw/images)'
    )
    
    parser.add_argument(
    '--labels',
    default='data/labels',
    help='æ ‡ç­¾æ–‡ä»¶ç›®å½• (é»˜è®¤: data/labels)'
    )
    
    parser.add_argument(
        '-o', '--output',
    default='data',
    help='è¾“å‡ºæ ¹è·¯å¾„ (é»˜è®¤: data)'
    )
    
    parser.add_argument(
        '--train',
        type=float,
        default=0.8,
        help='è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤: 0.8)'
    )
    
    parser.add_argument(
        '--val',
        type=float,
        default=0.1,
        help='éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.1)'
    )
    
    parser.add_argument(
        '--test',
        type=float,
        default=0.1,
        help='æµ‹è¯•é›†æ¯”ä¾‹ (é»˜è®¤: 0.1)'
    )
    
    parser.add_argument(
        '--by-class',
        action='store_true',
        help='æŒ‰ç±»åˆ«å¹³è¡¡åˆ†å‰²'
    )
    
    parser.add_argument(
        '--seed',
        type=int,
        default=42,
        help='éšæœºç§å­ (é»˜è®¤: 42)'
    )
    
    parser.add_argument(
        '--image-extensions',
        nargs='+',
        default=['.jpg', '.jpeg', '.png', '.bmp', '.tiff'],
        help='æ”¯æŒçš„å›¾åƒæ‰©å±•å'
    )
    
    parser.add_argument(
        '--create-yaml',
        action='store_true',
        help='åˆ›å»ºYOLOæ•°æ®é›†é…ç½®æ–‡ä»¶'
    )
    
    parser.add_argument(
        '--classes',
        help='ç±»åˆ«åç§°æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '--dataset-name',
        default='custom_dataset',
        help='æ•°æ®é›†åç§° (é»˜è®¤: custom_dataset)'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='è¯¦ç»†è¾“å‡º'
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.verbose)
    logger = logging.getLogger(__name__)
    
    try:
        # éªŒè¯åˆ†å‰²æ¯”ä¾‹
        if not validate_ratios(args.train, args.val, args.test):
            sys.exit(1)
        
        print(f"ğŸš€ å¼€å§‹æ•°æ®é›†åˆ†å‰²...")
        print(f"   è¾“å…¥: {args.input}")
        print(f"   è¾“å‡º: {args.output}")
        print(f"   æ¯”ä¾‹: è®­ç»ƒ={args.train}, éªŒè¯={args.val}, æµ‹è¯•={args.test}")
        print(f"   æ–¹æ³•: {'æŒ‰ç±»åˆ«å¹³è¡¡' if args.by_class else 'éšæœºåˆ†å‰²'}")
        print(f"   ç§å­: {args.seed}")
        
        # åˆå§‹åŒ–åˆ†å‰²å™¨
        splitter = DatasetSplitter(seed=args.seed)
        
        # æ‰§è¡Œåˆ†å‰²
        if args.by_class:
            results = splitter.split_by_class(
                args.input,
                args.output,
                args.train,
                args.val,
                args.test
            )
            
            print(f"\nğŸ“Š æŒ‰ç±»åˆ«åˆ†å‰²ç»“æœ:")
            for class_id, counts in results.items():
                print(f"   ç±»åˆ« {class_id}: æ€»è®¡={counts['total']}, "
                      f"è®­ç»ƒ={counts['train']}, éªŒè¯={counts['val']}, æµ‹è¯•={counts['test']}")
        else:
            results = splitter.split_by_ratio(
                data_dir=args.input,
                labels_dir=args.labels,
                output_dir=args.output,
                train_ratio=args.train,
                val_ratio=args.val,
                test_ratio=args.test,
                image_extensions=args.image_extensions
            )
            
            print(f"\nğŸ“Š åˆ†å‰²ç»“æœ:")
            for split_name, counts in results.items():
                print(f"   {split_name}: å›¾åƒ={counts['images']}, æ ‡ç­¾={counts['labels']}")
        
        # åˆ›å»ºYOLOé…ç½®æ–‡ä»¶
        if args.create_yaml:
            class_names = []
            
            if args.classes:
                try:
                    class_names = read_classes_file(args.classes)
                    print(f"ğŸ“‹ ä»æ–‡ä»¶è¯»å–ç±»åˆ«: {args.classes}")
                except Exception as e:
                    print(f"âš ï¸  æ— æ³•è¯»å–ç±»åˆ«æ–‡ä»¶: {e}")
            
            if not class_names:
                # å°è¯•ä»è¾“å‡ºç›®å½•æ‰¾åˆ°classes.txt
                classes_file = Path(args.output) / 'classes.txt'
                if classes_file.exists():
                    class_names = read_classes_file(str(classes_file))
                    print(f"ğŸ“‹ ä»è¾“å‡ºç›®å½•è¯»å–ç±»åˆ«: {classes_file}")
                else:
                    print("âš ï¸  æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«åç§°")
                    class_names = ['class_0', 'class_1']  # é»˜è®¤ç±»åˆ«
            
            yaml_file = splitter.create_yolo_dataset_yaml(
                args.output,
                class_names,
                args.dataset_name
            )
            
            print(f"ğŸ“„ YOLOé…ç½®æ–‡ä»¶: {yaml_file}")
        
        print(f"\nâœ… æ•°æ®é›†åˆ†å‰²å®Œæˆ!")
        print(f"   è¾“å‡ºç›®å½•: {args.output}")
        
        # æ˜¾ç¤ºè¾“å‡ºç›®å½•ç»“æ„
        output_path = Path(args.output)
        if output_path.exists():
            print(f"\nğŸ“ è¾“å‡ºç›®å½•ç»“æ„:")
            for item in sorted(output_path.iterdir()):
                if item.is_dir():
                    image_count = len(list((item / 'images').glob('*'))) if (item / 'images').exists() else 0
                    label_count = len(list((item / 'labels').glob('*.txt'))) if (item / 'labels').exists() else 0
                    print(f"   {item.name}/")
                    print(f"     â”œâ”€â”€ images/ ({image_count} æ–‡ä»¶)")
                    print(f"     â””â”€â”€ labels/ ({label_count} æ–‡ä»¶)")
                else:
                    print(f"   {item.name}")
        
        # è·å–ç±»åˆ«å
        class_names = []
        if args.classes:
            try:
                class_names = read_classes_file(args.classes)
            except Exception as e:
                print(f"âš ï¸  æ— æ³•è¯»å–ç±»åˆ«æ–‡ä»¶: {e}")
        if not class_names:
            # è‡ªåŠ¨æŸ¥æ‰¾
            candidates = [
                output_path / 'classes.txt',
                output_path / 'labels' / 'classes.txt'
            ]
            for classes_file in candidates:
                if classes_file.exists():
                    class_names = read_classes_file(str(classes_file))
                    print(f"ğŸ“‹ ä» {classes_file} è¯»å–ç±»åˆ«")
                    break
            if not class_names:
                print("âš ï¸  æœªæ‰¾åˆ°ç±»åˆ«æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«åç§°")
                class_names = ['class_0', 'class_1']

        write_data_yaml(output_path, class_names)
        
        # æ¸…ç†æ ‡ç­¾ç›®å½•
        labels_dir = Path(args.labels)
        if labels_dir.exists():
            try:
                shutil.rmtree(labels_dir)
                print(f"ğŸ§¹ å·²åˆ é™¤æ ‡ç­¾ç›®å½•: {labels_dir}")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æ ‡ç­¾ç›®å½•å¤±è´¥: {e}")
        
        logger.info("æ•°æ®é›†åˆ†å‰²å®Œæˆ")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ åˆ†å‰²å¤±è´¥: {e}")
        logger.error(f"åˆ†å‰²å¤±è´¥: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
